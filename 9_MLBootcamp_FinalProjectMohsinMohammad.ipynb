{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SmartEngineer1/FLCMLBootcamp25Mohsin/blob/main/9_MLBootcamp_FinalProjectMohsinMohammad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Bootcamp 2025\n",
        "\n",
        "### Final Project: Train a Deep Learning model to identify Grocery item"
      ],
      "metadata": {
        "id": "DoJf9K5qna65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "W9Dh8fuk22i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters (User Configurable)\n",
        "\n",
        "random_seed = 42  #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n"
      ],
      "metadata": {
        "id": "zKOJDWUw4ny8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "kLpx5KTd5JEI",
        "outputId": "e3e85306-34ca-4154-c770-819eeab34202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Create directory 'Datasets/GroceryStoreDataset', unzip the shared dataset in it and mount the Google Drive\n",
        "# The original dataset used is: https://www.kaggle.com/datasets/validmodel/grocery-store-dataset?resource=download and it has been reduced further for our use-case\n",
        "data_dir = '/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset'  # Mount dataset in Google Drive"
      ],
      "metadata": {
        "id": "i9aVO01L27cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "DiJakegpcKuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e217a94e-23b7-4922-efb2-38d3253ecd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_class_names(csv_file_path):\n",
        "    \"\"\"\n",
        "    Extracts class names from a CSV file and returns them as a list.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path (str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing a list of class names and the number of classes.\n",
        "               Returns (None, 0) if the file does not exist or an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(csv_file_path, 'r') as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip header row if it exists\n",
        "            class_names = [row[2] for row in reader]  # Assuming class names are in the first column\n",
        "            class_names = sorted(set(class_names))\n",
        "        return class_names, len(class_names)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{csv_file_path}' not found.\")\n",
        "        return None, 0\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, 0"
      ],
      "metadata": {
        "id": "0czv7aeM3wTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "u8SYV_DN4HLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify that all folders are accessible from mounted Google Drive\n",
        "for x in ['train', 'test']:\n",
        "  path_new = os.path.join(data_dir, x)\n",
        "  print(path_new)\n",
        "  for folder in os.listdir(path_new):\n",
        "    folder_path = os.path.join(path_new, folder)\n",
        "    print(folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzWojEfRI_mG",
        "outputId": "fdd9d831-bea9-42d9-e7fe-03c754436191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Peach\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Pineapple\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Pepper\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Leek\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Orange\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Regular-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Papaya\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Sweet-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Garlic\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Zucchini\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Ginger\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Passion-Fruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Mango\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Solid-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Banana\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Cabbage\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Red-Beet\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Yellow-Onion\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Red-Delicious\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Asparagus\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Lime\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Cantaloupe\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Red-Grapefruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Plum\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Carrots\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Granny-Smith\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Watermelon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Lemon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Vine-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Nectarine\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Cucumber\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Kiwi\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Pomegranate\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/train/Avocado\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Leek\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Orange\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Pepper\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Pineapple\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Garlic\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Sweet-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Regular-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Peach\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Papaya\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Zucchini\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Asparagus\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Red-Delicious\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Cabbage\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Mango\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Passion-Fruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Ginger\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Banana\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Yellow-Onion\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Solid-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Red-Beet\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Lime\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Cucumber\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Nectarine\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Plum\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Carrots\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Red-Grapefruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Cantaloupe\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Watermelon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Vine-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Granny-Smith\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Lemon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Avocado\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Kiwi\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Pomegranate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'test']}  # Assuming you have train and test folders\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "\n",
        "print(f\"Dataset sizes: {dataset_sizes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxlSKZia4Nnq",
        "outputId": "36cc250d-c07f-4558-9c2b-04ca37de4bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizes: {'train': 1239, 'test': 1205}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "class_names = image_datasets['test'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQfGgMDJJzbS",
        "outputId": "89383149-ec68-4437-ea26-835981163872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Asparagus', 'Avocado', 'Banana', 'Cabbage', 'Cantaloupe', 'Carrots', 'Cucumber', 'Garlic', 'Ginger', 'Granny-Smith', 'Kiwi', 'Leek', 'Lemon', 'Lime', 'Mango', 'Nectarine', 'Orange', 'Papaya', 'Passion-Fruit', 'Peach', 'Pepper', 'Pineapple', 'Plum', 'Pomegranate', 'Red-Beet', 'Red-Delicious', 'Red-Grapefruit', 'Regular-Tomato', 'Solid-Potato', 'Sweet-Potato', 'Vine-Tomato', 'Watermelon', 'Yellow-Onion', 'Zucchini']\n",
            "34\n",
            "['Asparagus', 'Avocado', 'Banana', 'Cabbage', 'Cantaloupe', 'Carrots', 'Cucumber', 'Garlic', 'Ginger', 'Granny-Smith', 'Kiwi', 'Leek', 'Lemon', 'Lime', 'Mango', 'Nectarine', 'Orange', 'Papaya', 'Passion-Fruit', 'Peach', 'Pepper', 'Pineapple', 'Plum', 'Pomegranate', 'Red-Beet', 'Red-Delicious', 'Red-Grapefruit', 'Regular-Tomato', 'Solid-Potato', 'Sweet-Potato', 'Vine-Tomato', 'Watermelon', 'Yellow-Onion', 'Zucchini']\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_channel(matrix):\n",
        "  return matrix.repeat(3, 1, 1) # 1s are due to height and weight\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    #transforms.Grayscale(channel = 3), #cause im getting the error message\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(fix_channel),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "print(f\"Train dataset classes: {train_loader.dataset.classes}\")\n",
        "print(f\"Test dataset classes: {test_loader.dataset.classes}\")\n",
        "\n",
        "splitter_web = {\n",
        "    #something gets in here\n",
        "}\n",
        "\n",
        "taser_test = {}\n",
        "grenade_train = {}\n",
        "\n",
        "\n",
        "total_class_train = {}\n",
        "total_class_test = {}\n",
        "\n",
        "for image, label in train_dataset:\n",
        "  if label in total_class_train:\n",
        "      total_class_train[label] += 1\n",
        "\n",
        "  else:\n",
        "      total_class_train[label] = 1\n",
        "\n",
        "  if label not in splitter_web:\n",
        "      splitter_web[label] = []\n",
        "  splitter_web[label].append(image)\n",
        "\n",
        "\n",
        "print(f\"Trained class {total_class_train}\")\n",
        "\n",
        "for image, label in test_dataset:\n",
        "  if label in total_class_test:\n",
        "      total_class_test[label] += 1\n",
        "\n",
        "  else:\n",
        "      total_class_test[label] = 1\n",
        "\n",
        "  if label not in splitter_web:\n",
        "      splitter_web[label] = []\n",
        "  splitter_web[label].append(image)\n",
        "\n",
        "#THHHHHE SPLLLLIIIIITTT\n",
        "for label, imagelist in splitter_web.items():\n",
        "  grenade_trainer, taser_tester = train_test_split(imagelist, test_size = 0.5, random_state = 42)\n",
        "  taser_test[label] = taser_tester\n",
        "  grenade_train[label] = grenade_trainer\n",
        "\n",
        "print(f\"Tested class {total_class_test}\")\n",
        "\n",
        "#If i called the confusion matrix and the rest here it will work\n"
      ],
      "metadata": {
        "id": "7PZWZe0r42BH",
        "outputId": "b1597948-06e0-4f35-ab76-7bba1c1bca2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset classes: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
            "Test dataset classes: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
            "Trained class {5: 5421, 0: 5923, 4: 5842, 1: 6742, 9: 5949, 2: 5958, 3: 6131, 6: 5918, 7: 6265, 8: 5851}\n",
            "Tested class {7: 1028, 2: 1032, 1: 1135, 0: 980, 4: 982, 9: 1009, 5: 892, 6: 958, 3: 1010, 8: 974}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained EfficientNetB4\n",
        "model = models.efficientnet_b4(pretrained=True)\n",
        "\n",
        "# Modify the classifier\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "-HTLL6AAcz85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, class_names):\n",
        "  img = Image.open(image_path).convert('RGB')\n",
        "  img_t = data_transforms['test'](img).unsqueeze(0)\n",
        "  img_t = img_t.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    out = model(img_t)\n",
        "    _, index = torch.max(out, 1)\n",
        "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    print(f\"Predicted Class: {class_names[index[0]]}, Confidence: {percentage[index[0]].item():.2f}%\")"
      ],
      "metadata": {
        "id": "xiQz7UkGmp-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        now = datetime.now()\n",
        "        print(now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            i = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                i += 1\n",
        "                if i % 10 == 0:\n",
        "                    print(f\"Batch {i} of {len(dataloaders[phase])}\")\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            history[f'{phase}_loss'].append(epoch_loss)\n",
        "            history[f'{phase}_acc'].append(epoch_acc)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def result():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.to(device)\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "\n",
        "          _, predicted = torch.max(output.data, 1)\n",
        "          total += target.size(0)\n",
        "          correct += (predicted == target).sum().item()\n",
        "          all_preds.extend(predicted.cpu().numpy())\n",
        "          all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "\n",
        "    #to make it more easier to read for myself\n",
        "    myacc = correct / total\n",
        "    myfone = f1_score(all_targets, all_preds, average=None)\n",
        "    myprec = precision_score(all_targets, all_preds, average=None)\n",
        "    myrecall = recall_score(all_targets, all_preds, average=None)\n",
        "    mymat = confusion_matrix(all_targets, all_preds)\n",
        "    return myacc, myfone, myprec, myrecall, mymat\n",
        "\n",
        "\n",
        "\n",
        "donemodel, donehistory = train_model(model, criterion, optimizer, num_epochs=25)\n",
        "print(f\"The model: {donemodel}\")\n",
        "print(f\"The history: {donehistory}\")\n",
        "\n",
        "\n",
        "\n",
        "doneacc, donefone, doneprec, donerecall, donemat = result()\n",
        "print(f\"The Accuracy: {doneacc}\")\n",
        "print(f\"The F1 score: {donefone}\")\n",
        "print(f\"The Precision score: {doneprec}\")\n",
        "print(f\"The Recall score: {donerecall}\")\n",
        "print(f\"The Confusion matrix: {donemat}\")\n",
        "\n",
        "##time for the 6x4 thing. lots or resources spent reviewring and studying lol\n",
        "model.eval()\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "      output = model(data)\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      grid, axes = plt.subplots(6, 4, figsize = (12, 18))\n",
        "\n",
        "      axes = axes.flatten()\n",
        "\n",
        "      for i in range(24):\n",
        "        axes[i].imshow(data[i].cpu().permute(1, 2, 0).numpy())\n",
        "        axes[i].set_title(f\"Real {label[i].item()} vs predicted {predicted[i].item()}\")"
      ],
      "metadata": {
        "id": "uYHty5B3c0tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before training\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Mango/Mango_002.jpg', model, class_names)\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/test/Pineapple/Pineapple_021.jpg', model, class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JS0IIf3nomp",
        "outputId": "085b7708-824c-486a-a206-9dea38abb3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: Zucchini, Confidence: 3.62%\n",
            "Predicted Class: Zucchini, Confidence: 3.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = train_model(model, criterion, optimizer, num_epochs=18)\n"
      ],
      "metadata": {
        "id": "XmK6M7JfdI6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37e27dc-7d46-49e5-c462-d4bf3989b52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/17\n",
            "2025-04-14 06:05:55\n",
            "----------\n",
            "Batch 10 of 78\n",
            "Batch 20 of 78\n",
            "Batch 30 of 78\n",
            "Batch 40 of 78\n",
            "Batch 50 of 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\n",
        "    'train_loss': history['train_loss'],\n",
        "    'train_acc': [t.cpu().item() for t in history['train_acc']],\n",
        "    'test_loss': history['test_loss'],\n",
        "    'test_acc': [t.cpu().item() for t in history['test_acc']]\n",
        "}\n",
        "\n",
        "print(metrics)\n",
        "\n",
        "# Plot the training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(metrics['train_loss'], label='Train Loss')\n",
        "plt.plot(metrics['test_loss'], label='Test Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(metrics['train_acc'], label='Train Accuracy')\n",
        "plt.plot(metrics['test_acc'], label='Test Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t16NKwwMk8Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained model\n",
        "torch.save(model, '/content/drive/MyDrive/Datasets/GroceryStoreDataset/GroceryStoreDataset/complete_model.pth')\n"
      ],
      "metadata": {
        "id": "UIVE84gMkWdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Mango/Mango_002.jpg', model, class_names)\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Pineapple/Pineapple_021.jpg', model, class_names)\n"
      ],
      "metadata": {
        "id": "dK1rXYLzdRf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project:\n",
        "\n",
        "1. Perform exploratory data analysis on the 'train' and 'test' datasets to calculate class imbalance (by comparing 'samples per class' across all the classes)\n",
        "2. Print confusion matrix, precision, recall and f1-score\n",
        "3. Show a grid of 6x4 images, with actual and predicted class for each of those\n",
        "\n",
        "\n",
        "### Bonus Project:\n",
        "\n",
        "1. Allow user to input the items they shopped using images, use model to identify grocery item based on confidence threshold. If confidence is low, ask user to manually input the item.\n",
        "2. Update the digital grocery cart\n",
        "3. Process the transaction by generating a transaction receipt\n"
      ],
      "metadata": {
        "id": "LTcyENYCtxXm"
      }
    }
  ]
}